INFO:  Setting up logging folder : distilled_model_library/cifar10/convnet2/2022-12-30-22:48:51.429602_student_T=5.0_Lambda=0.95_teacher_convnet6_with_loss_cross_entropy
INFO:  Namespace(Lambda=0.95, T=5.0, alpha=5.0, beta=1.0, chain_length=None, checkpoint='distilled_model_library', current_time='', dataset='cifar10', epochs=1, exp_name='', gamma=1, loss='cross_entropy', lr=0.1, lr_decay_factor=0.1, model='convnet2', momentum=0.9, optimizer='sgd', patience=10, prefix='', regularizer='l2', schedule_steps=[], scheduler='multistep', seed=42, start_epoch=0, teacher='convnet6', teacher_loss='cross_entropy', teacher_path='trained_model_library/cifar10/convnet6/2022-12-30-22:31:39.064664_cross_entropy', test_batch_size=100, train_batch_size=128, warmup=0, weight_decay=0.0001, workers=4)
INFO:  ['train_student.py', '--dataset', 'cifar10', '--model', 'convnet2', '--teacher', 'convnet6', '--teacher_path', 'trained_model_library/cifar10/convnet6/2022-12-30-22:31:39.064664_cross_entropy', '--teacher_loss', 'cross_entropy', '--lr', '0.1', '--epochs', '1', '--wd', '1e-4', '--train-batch-size', '128', '--checkpoint', 'distilled_model_library', '--T', '5', '--Lambda', '0.95']
INFO:  GPUs used: 1
INFO:  Using teacher model : convnet6
INFO:  loading teacher model from: trained_model_library/cifar10/convnet6/2022-12-30-22:31:39.064664_cross_entropy
INFO:  Using Vanilla KD with: T=5.0, Lambda=0.95
INFO:  Step sizes : [] | lr-decay-factor : 0.1
INFO:  training completed...
INFO:  The stats for best accuracy model on test set are as below:
INFO:  {'top1': 12.45, 'top3': 34.67, 'top5': 57.45, 'SCE': 0.012768679652176793, 'ECE': 0.01767222505360842}
